{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "CNN Dog Breed Classificiation"
      ],
      "metadata": {
        "id": "WFMXvL8IdF4g"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FioP3Qd1cXYB",
        "outputId": "07670bde-aac7-41ca-d89b-ac9e6a9cb126"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "annotations  archive.zip  images  sample_data\n"
          ]
        }
      ],
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "# unzip dataset\n",
        "with zipfile.ZipFile(\"archive.zip\", \"r\") as zip_ref:\n",
        "    zip_ref.extractall()\n",
        "\n",
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from genericpath import exists\n",
        "import os\n",
        "import shutil\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "assert os.path.isdir(\"images/Images\")\n",
        "\n",
        "for dir in [\"train\", \"val\", \"test\"]:\n",
        "    os.makedirs(os.path.join(\"dogs\", dir), exist_ok=True)\n",
        "\n",
        "classes = sorted(os.listdir(\"images/Images\"))\n",
        "\n",
        "train_ratio = 0.8\n",
        "\n",
        "# temp:\n",
        "val_ratio = 0.1\n",
        "test_ratio = 0.1\n",
        "\n",
        "for cls in classes:\n",
        "    cls_dir = os.path.join(\"images/Images\", cls)\n",
        "    imgs = [img for img in os.listdir(cls_dir)]\n",
        "\n",
        "    # splits train vs temp\n",
        "    train_imgs, temp_imgs = train_test_split(imgs, test_size=(1.0 - train_ratio), random_state=42)\n",
        "\n",
        "    # splits temp into val and test\n",
        "    val_size = val_ratio / (val_ratio + test_ratio)\n",
        "    val_imgs, test_imgs = train_test_split(temp_imgs, test_size=(1.0 - val_size), random_state=42)\n",
        "\n",
        "    def copy(file_list, dir):\n",
        "      dst_cls = os.path.join(\"dogs\", dir, cls)\n",
        "      os.makedirs(dst_cls, exist_ok=True)\n",
        "      for file in file_list:\n",
        "        src = os.path.join(cls_dir, file)\n",
        "        dst = os.path.join(dst_cls, file)\n",
        "\n",
        "        # print(dst, src)\n",
        "        shutil.copy(src, dst)\n",
        "\n",
        "    copy(train_imgs, \"train\")\n",
        "    copy(val_imgs,  \"val\")\n",
        "    copy(test_imgs, \"test\")\n"
      ],
      "metadata": {
        "id": "cBB6NidIdSgW"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torchvision import transforms, datasets, models\n",
        "from torch.utils.data import DataLoader, Subset\n",
        "\n",
        "batch = 32\n",
        "epochs = 4\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# transforms\n",
        "data_transforms = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.RandomResizedCrop(224, scale=(0.7, 1.0)), transforms.RandomHorizontalFlip(),\n",
        "        transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
        "        transforms.ToTensor(), transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),]),\n",
        "\n",
        "    'val': transforms.Compose([\n",
        "        transforms.Resize(256), transforms.CenterCrop(224), transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),]),\n",
        "\n",
        "    'test': transforms.Compose([\n",
        "        transforms.Resize(256), transforms.CenterCrop(224), transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),]),\n",
        "    }\n",
        "\n",
        "img_datasets = {\n",
        "    x: datasets.ImageFolder(root=os.path.join(\"dogs\", x), transform=data_transforms[x])\n",
        "    for x in ['train', 'val', 'test']}\n",
        "\n",
        "# MAX_TRAIN = 320000\n",
        "# MAX_VAL = 6400\n",
        "# MAX_TEST = 6400\n",
        "\n",
        "# subset_dataset = {}\n",
        "\n",
        "# for x, max_size in zip([\"train\", \"val\", \"test\"], [MAX_TRAIN, MAX_VAL, MAX_TEST]):\n",
        "#   full_dataset = img_datasets[x]\n",
        "\n",
        "#   indices = torch.randperm(len(full_dataset)).tolist()\n",
        "#   subset_indices = indices[:max_size]\n",
        "\n",
        "#   subset_dataset[x] = Subset(full_dataset, subset_indices)\n",
        "\n",
        "#   img_datasets[x] = subset_dataset[x]\n",
        "\n",
        "dataloaders = {\n",
        "    x: DataLoader(img_datasets[x], batch_size=batch, shuffle=(x ==\"train\"), num_workers=2)\n",
        "    for x in ['train', 'val', 'test']}\n",
        "\n",
        "dataset_sizes = {x: len(img_datasets[x]) for x in ['train', 'val', 'test']}\n",
        "# class_names = img_datasets['train'].dataset.classes\n",
        "class_names = img_datasets['train'].classes\n",
        "\n",
        "print(class_names)\n",
        "\n",
        "model = models.resnet18(pretrained=True)\n",
        "\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "in_features = model.fc.in_features\n",
        "model.fc = torch.nn.Linear(in_features, len(class_names))\n",
        "\n",
        "for param in model.fc.parameters():\n",
        "    param.requires_grad = True\n",
        "\n",
        "model = model.to(device)\n",
        "\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "\n",
        "# train function\n",
        "def train(model, dataloaders, dataset_sizes, device, num_epochs=25):\n",
        "    best_acc = 0.0\n",
        "    best_weigths = model.state_dict()\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print(f\"Epoch {epoch}/{num_epochs - 1}\")\n",
        "        print(\"-\" * 10)\n",
        "\n",
        "        for phase in [\"train\", \"val\"]:\n",
        "            if phase == \"train\":\n",
        "                model.train()\n",
        "            else:\n",
        "                model.eval()\n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "\n",
        "            for inputs, labels in dataloaders[phase]:\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                optimizer.zero_grad()\n",
        "                with torch.set_grad_enabled(phase == \"train\"):\n",
        "                    outputs = model(inputs)\n",
        "\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "                    loss = criterion(outputs, labels)\n",
        "\n",
        "                    if phase == \"train\":\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_corrects += torch.sum(preds == labels)\n",
        "\n",
        "            epoch_loss = running_loss / dataset_sizes[phase]\n",
        "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
        "\n",
        "            if phase == \"val\" and epoch_acc > best_acc:\n",
        "                best_acc = epoch_acc\n",
        "                best_weigths = model.state_dict()\n",
        "\n",
        "    model.load_state_dict(best_weigths)\n",
        "    return model\n",
        "\n",
        "# evaluate CNN\n",
        "def evaluate(model, dataloaders, dataset_sizes, device):\n",
        "    model.eval()\n",
        "    model.to(device)\n",
        "\n",
        "    running_corrects = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "      for inputs, labels in dataloaders[\"test\"]:\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        outputs = model(inputs)\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "\n",
        "        running_corrects += torch.sum(preds == labels)\n",
        "\n",
        "    test_acc = running_corrects.double() / dataset_sizes[\"test\"]\n",
        "\n",
        "    return test_acc\n",
        "\n",
        "model = train(model, dataloaders, dataset_sizes, device, num_epochs=epochs)\n",
        "test_acc = evaluate(model, dataloaders, dataset_sizes, device)\n",
        "print(\"Test Accuracy: {:.4f}\".format(test_acc))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FGEqA1IXxARA",
        "outputId": "55e0adc0-949b-416f-b8ae-c7b1c823898e"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['n02085620-Chihuahua', 'n02085782-Japanese_spaniel', 'n02085936-Maltese_dog', 'n02086079-Pekinese', 'n02086240-Shih-Tzu', 'n02086646-Blenheim_spaniel', 'n02086910-papillon', 'n02087046-toy_terrier', 'n02087394-Rhodesian_ridgeback', 'n02088094-Afghan_hound', 'n02088238-basset', 'n02088364-beagle', 'n02088466-bloodhound', 'n02088632-bluetick', 'n02089078-black-and-tan_coonhound', 'n02089867-Walker_hound', 'n02089973-English_foxhound', 'n02090379-redbone', 'n02090622-borzoi', 'n02090721-Irish_wolfhound', 'n02091032-Italian_greyhound', 'n02091134-whippet', 'n02091244-Ibizan_hound', 'n02091467-Norwegian_elkhound', 'n02091635-otterhound', 'n02091831-Saluki', 'n02092002-Scottish_deerhound', 'n02092339-Weimaraner', 'n02093256-Staffordshire_bullterrier', 'n02093428-American_Staffordshire_terrier', 'n02093647-Bedlington_terrier', 'n02093754-Border_terrier', 'n02093859-Kerry_blue_terrier', 'n02093991-Irish_terrier', 'n02094114-Norfolk_terrier', 'n02094258-Norwich_terrier', 'n02094433-Yorkshire_terrier', 'n02095314-wire-haired_fox_terrier', 'n02095570-Lakeland_terrier', 'n02095889-Sealyham_terrier', 'n02096051-Airedale', 'n02096177-cairn', 'n02096294-Australian_terrier', 'n02096437-Dandie_Dinmont', 'n02096585-Boston_bull', 'n02097047-miniature_schnauzer', 'n02097130-giant_schnauzer', 'n02097209-standard_schnauzer', 'n02097298-Scotch_terrier', 'n02097474-Tibetan_terrier', 'n02097658-silky_terrier', 'n02098105-soft-coated_wheaten_terrier', 'n02098286-West_Highland_white_terrier', 'n02098413-Lhasa', 'n02099267-flat-coated_retriever', 'n02099429-curly-coated_retriever', 'n02099601-golden_retriever', 'n02099712-Labrador_retriever', 'n02099849-Chesapeake_Bay_retriever', 'n02100236-German_short-haired_pointer', 'n02100583-vizsla', 'n02100735-English_setter', 'n02100877-Irish_setter', 'n02101006-Gordon_setter', 'n02101388-Brittany_spaniel', 'n02101556-clumber', 'n02102040-English_springer', 'n02102177-Welsh_springer_spaniel', 'n02102318-cocker_spaniel', 'n02102480-Sussex_spaniel', 'n02102973-Irish_water_spaniel', 'n02104029-kuvasz', 'n02104365-schipperke', 'n02105056-groenendael', 'n02105162-malinois', 'n02105251-briard', 'n02105412-kelpie', 'n02105505-komondor', 'n02105641-Old_English_sheepdog', 'n02105855-Shetland_sheepdog', 'n02106030-collie', 'n02106166-Border_collie', 'n02106382-Bouvier_des_Flandres', 'n02106550-Rottweiler', 'n02106662-German_shepherd', 'n02107142-Doberman', 'n02107312-miniature_pinscher', 'n02107574-Greater_Swiss_Mountain_dog', 'n02107683-Bernese_mountain_dog', 'n02107908-Appenzeller', 'n02108000-EntleBucher', 'n02108089-boxer', 'n02108422-bull_mastiff', 'n02108551-Tibetan_mastiff', 'n02108915-French_bulldog', 'n02109047-Great_Dane', 'n02109525-Saint_Bernard', 'n02109961-Eskimo_dog', 'n02110063-malamute', 'n02110185-Siberian_husky', 'n02110627-affenpinscher', 'n02110806-basenji', 'n02110958-pug', 'n02111129-Leonberg', 'n02111277-Newfoundland', 'n02111500-Great_Pyrenees', 'n02111889-Samoyed', 'n02112018-Pomeranian', 'n02112137-chow', 'n02112350-keeshond', 'n02112706-Brabancon_griffon', 'n02113023-Pembroke', 'n02113186-Cardigan', 'n02113624-toy_poodle', 'n02113712-miniature_poodle', 'n02113799-standard_poodle', 'n02113978-Mexican_hairless', 'n02115641-dingo', 'n02115913-dhole', 'n02116738-African_hunting_dog']\n",
            "Epoch 0/3\n",
            "----------\n",
            "Epoch 1/3\n",
            "----------\n",
            "Epoch 2/3\n",
            "----------\n",
            "Epoch 3/3\n",
            "----------\n",
            "Test Accuracy: 0.7725\n"
          ]
        }
      ]
    }
  ]
}